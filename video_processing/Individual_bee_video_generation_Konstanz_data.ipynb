{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "904386ce",
   "metadata": {},
   "source": [
    "# Notebook to generate one video per bee, cropped to the area around the bee, for videos in the Konstanz dataset (scented bee petri dish videos)\n",
    "\n",
    "- Pose data is exported to CSV-files along with the videos (I only generated videos and exported pose data to CSV for some of the videos from the hex-group)\n",
    "- This notebook is currently working with pixel values configured for the 1920x1080 videos but it could be adapted for the smaller videos in the same way as in *Trophallaxis_video_generation_Konstanz_data.ipynb*, by multiplying all pixels values with a ratio adjustment value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from concurrent.futures import ThreadPoolExecutor as PoolExecutor\n",
    "import skimage.io\n",
    "import imageio\n",
    "from datetime import datetime\n",
    "import bb_behavior.utils.images\n",
    "from typing import Tuple\n",
    "import cv2\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import glob\n",
    "import logging\n",
    "import csv\n",
    "from sortedcontainers import SortedDict\n",
    "from video_utils import CustomVideoManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e301974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='indiv_video_gen_konst_data.log',\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# write info to console\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "console_handler.setFormatter(logging.Formatter(\n",
    "    '%(levelname)s - %(message)s'\n",
    "))\n",
    "logging.getLogger().addHandler(console_handler)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Starting video generation ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2b27d",
   "metadata": {},
   "source": [
    "## Set global variables\n",
    "\n",
    "| Variable | Explanation |\n",
    "| --- | --- |\n",
    "| GENERATE_VIDEOS | Whether to generate videos; if False then only the CSV for the pose data in the videos is generated (much faster) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6052820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to False if you want to only process and output the pose data\n",
    "GENERATE_VIDEOS = True\n",
    "\n",
    "\n",
    "VIDEO_ROOT = '/mnt/windows-ssd/BeesData/scented_bees_video_files/'\n",
    "CACHE_PATH = '/mnt/windows-ssd/BeesData/tmp/'\n",
    "POSTURE_FILES_PATH = '/mnt/windows-ssd/BeesData/scented_bees_posture_files/'\n",
    "VIDEO_OUTPUT_PATH = '/mnt/windows-ssd/BeesData/videos_single_bees/'\n",
    "MARKER_DATA_OUTPUT_PATH = '/mnt/windows-ssd/trophallaxis_detection_code/data/marker_data_konstanz'\n",
    "\n",
    "N_JOBS = 16     # number of parallel jobs for frame extraction\n",
    "FRAME_RATE = 50\n",
    "FRAMES_PER_MINUTE = 60 * 50\n",
    "# cut off the first five minutes of frames because bees are still waking up\n",
    "MINUTES_CUTOFF_START = 5\n",
    "FRAME_CUTOFF_START = MINUTES_CUTOFF_START * FRAMES_PER_MINUTE\n",
    "\n",
    "BODYPARTS_HEADER = [\n",
    "    'bodyparts', 'left_antenna', 'left_antenna', 'left_antenna',\n",
    "    'right_antenna', 'right_antenna', 'right_antenna',\n",
    "    'head', 'head', 'head',\n",
    "    'thorax', 'thorax', 'thorax',\n",
    "    'abdomen_tip', 'abdomen_tip', 'abdomen_tip'\n",
    "]\n",
    "COORDS_HEADER = [\n",
    "    'coords', \n",
    "    'x', 'y', 'likelihood', \n",
    "    'x', 'y', 'likelihood', \n",
    "    'x', 'y', 'likelihood',\n",
    "    'x', 'y', 'likelihood', \n",
    "    'x', 'y', 'likelihood'\n",
    "]\n",
    "COLS_BODYPARTS_EXPORT = [\n",
    "    \"left_antenna_x\", \"left_antenna_y\", \"left_antenna_conf\",\n",
    "    \"right_antenna_x\", \"right_antenna_y\", \"right_antenna_conf\",\n",
    "    \"head_x\", \"head_y\", \"head_conf\",\n",
    "    \"thorax_x\", \"thorax_y\", \"thorax_conf\",\n",
    "    \"abdomen_tip_x\", \"abdomen_tip_y\", \"abdomen_tip_conf\"\n",
    "]\n",
    "\n",
    "#############################################################################################\n",
    "# wcentroid is based on centroid weighted by pixel values, \n",
    "# pcentroid is based on posture centroid (the center of the midline)\n",
    "# centroid is center of mass of all thresholded pixels\n",
    "# nothing after the hashtag means based on head position\n",
    "#############################################################################################\n",
    "COLS_TO_EXCLUDE = [\n",
    "    'tracklets','tracklet_vxys','video_size', 'id', 'frame_rate', \n",
    "    'ACCELERATION#pcentroid', 'AX', 'ANGULAR_A#centroid',#'ACCELERATION#wcentroid',\n",
    "    'ANGULAR_V#centroid', 'BORDER_DISTANCE#pcentroid', 'AY', 'MIDLINE_OFFSET',\n",
    "    'SPEED#wcentroid', 'SPEED#pcentroid', 'SPEED', 'VX', 'VY', 'X#wcentroid', \n",
    "    'Y#wcentroid', 'midline_length', 'midline_segment_length', 'midline_x', \n",
    "    'midline_y', 'missing', 'normalized_midline', 'num_pixels', 'timestamp'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51edae4b",
   "metadata": {},
   "source": [
    "## Build the dataframe from tracking and pose data\n",
    "\n",
    "Pose data fields: <br>\n",
    "\n",
    "poseX0, poseY0: left antenna <br>\n",
    "poseX1, poseY1: right antenna <br>\n",
    "poseX2, poseY2: proboscis <br>\n",
    "poseX3, poseY3: head <br>\n",
    "poseX4, poseY4: thorax <br>\n",
    "poseX5, poseY5: abdomen (the tip) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9592fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe() -> pd.DataFrame:\n",
    "    frame_id_offset = 0\n",
    "    video_names = sorted(glob.glob(POSTURE_FILES_PATH + 'hex_*.npz'))\n",
    "    for file_idx, file in enumerate(video_names):\n",
    "        data = np.load(file)\n",
    "        keys = data.files\n",
    "\n",
    "        # Figure out how many rows (we’ll use 'time' as canonical—but any 1D key works)\n",
    "        n = data['time'].shape[0]\n",
    "\n",
    "        columns = {}\n",
    "\n",
    "        for k in keys:\n",
    "            if k in COLS_TO_EXCLUDE:\n",
    "                continue\n",
    "            v = data[k]\n",
    "            \n",
    "            # Scalar → broadcast to length n\n",
    "            if np.ndim(v) == 0 or k == 'cm_per_pixel':\n",
    "                columns[k] = np.repeat(v.item(), n)\n",
    "            # 1-D array (including object-dtype) → straight in\n",
    "            elif v.ndim == 1:\n",
    "                columns[k] = v\n",
    "            # Multi-D numeric array → flatten trailing dims into separate columns\n",
    "            else:\n",
    "                # reshape to (n_rows, -1)\n",
    "                flat = v.reshape(n, -1)\n",
    "                for i in range(flat.shape[1]):\n",
    "                    columns[f\"{k}_{i}\"] = flat[:, i]\n",
    "\n",
    "        # Build the DataFrame\n",
    "        df_file = pd.DataFrame(columns)\n",
    "        data_filename = (file.split(\"/\")[-1]).split(\".\")[0]\n",
    "        df_file['data_filename'] = data_filename\n",
    "\n",
    "        # X and Y are in cm (convert to px)\n",
    "        df_file = df_file.rename(columns={'cm_per_pixel': 'cm_per_px'})\n",
    "        cm_per_px = df_file['cm_per_px'].iloc[0]\n",
    "        df_file['x_pixels'] = np.round(df_file['X'] / cm_per_px)\n",
    "        df_file['y_pixels'] = np.round(df_file['Y'] / cm_per_px)\n",
    "\n",
    "        df_file['bee_id'] = data['id'][0]\n",
    "        df_file['frame_index'] = df_file['frame'].astype(int)\n",
    "        df_file = df_file.rename(columns={\n",
    "            'ANGLE': 'orientation', \n",
    "            'poseX0': 'left_antenna_x', 'poseY0': 'left_antenna_y',\n",
    "            'poseX1': 'right_antenna_x', 'poseY1': 'right_antenna_y',\n",
    "            'poseX2': 'proboscis_x', 'poseY2': 'proboscis_y',\n",
    "            'poseX3': 'head_x', 'poseY3': 'head_y',\n",
    "            'poseX4': 'thorax_x', 'poseY4': 'thorax_y',\n",
    "            'poseX5': 'abdomen_tip_x', 'poseY5': 'abdomen_tip_y',\n",
    "            'ACCELERATION#wcentroid': 'accel'\n",
    "        })\n",
    "        df_file = df_file.drop(columns='frame')\n",
    "\n",
    "        df_file = df_file[df_file.frame_index >= FRAME_CUTOFF_START]\n",
    "        \n",
    "        frames_cnt = len(df_file['frame_index'])\n",
    "        df_file['frame_id'] = df_file['frame_index'] + frame_id_offset\n",
    "        if (file_idx+1) % 4 == 0:\n",
    "            frame_id_offset += frames_cnt\n",
    "\n",
    "        df_files.append(df_file)\n",
    "    df = pd.concat(df_files)\n",
    "    df['video_filename'] = VIDEO_ROOT + df['data_filename'].str.split('_fish').str[0] + \".mp4\"\n",
    "    df[['left_antenna_conf', 'right_antenna_conf', 'proboscis_conf', 'head_conf', 'thorax_conf', 'abdomen_tip_conf']] = 1.0\n",
    "    return df\n",
    "\n",
    "df_files = []\n",
    "df = build_dataframe()\n",
    "\n",
    "print(df.keys())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454eee41",
   "metadata": {},
   "source": [
    "## Combine the tracking dataframe with the video file dataframe\n",
    "\n",
    "The Custom video manager is used for caching and extracting frames from videos as well as saving frames to videos. It is partly adapted from a notebook by Jacob Davidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4165f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_manager = CustomVideoManager(VIDEO_ROOT, CACHE_PATH, VIDEO_OUTPUT_PATH, max_workers=16)\n",
    "video_manager.clear_video_cache()\n",
    "\n",
    "videos_df = video_manager.get_all_video_files()\n",
    "df = pd.merge(df, videos_df, on='video_filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7826d528",
   "metadata": {},
   "source": [
    "## Get the cropped images for the bees with the corresponding body masks (for other bees)\n",
    "This cell was adapted from https://github.com/nebw/unsupervised_behaviors/blob/master/unsupervised_behaviors/data.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de680e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frames(\n",
    "    detections: pd.DataFrame,\n",
    "    video_manager: CustomVideoManager,\n",
    "    image_size_px: int = 272,\n",
    "    image_crop_px: int = 40,\n",
    "    body_center_offset_px: int = 35,\n",
    "    body_mask_length_px: int = 96,\n",
    "    body_mask_width_px: int = 64,\n",
    "    egocentric: bool = True,\n",
    "    generate_videos: bool = True,\n",
    "    use_clahe: bool = True,\n",
    "    clahe_kernel_size_px: int = 25,\n",
    "    n_jobs: int = -1\n",
    ") -> Tuple[np.ndarray, np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"Get cached images and for each bee, crop them to the area around this bee and optionally rotate \n",
    "       image region so that the bee is egocentrically aligned. Create body mask to hide other bees (could \n",
    "       be removed). Adjust keypoint data to this new image region by using translation and rotation.\n",
    "\n",
    "    Args:\n",
    "        detections (pd.DataFrame): Dataframe with detections.\n",
    "        video_manager (CustomVideoManager): Manages cache.\n",
    "        image_size_px (int, optional): Image size before cropping. Defaults to 272.\n",
    "        image_crop_px (int, optional): Crop amount after rotation. Defaults to 40.\n",
    "        body_center_offset_px (int, optional): Offset between body center and bee coordinates (head). Defaults to 35.\n",
    "        body_mask_length_px (int, optional): Length of body mask. Defaults to 96.\n",
    "        body_mask_width_px (int, optional): Width of body mask. Defaults to 64.\n",
    "        egocentric (bool, optional): Whether to rotate the frames so that the focus bee is egocentrically aligned. \n",
    "            Defaults to True.\n",
    "        generate_videos (bool, optional): Whether to generate video clips. Defaults to True.\n",
    "        use_clahe (bool, optional): Process entire frame using CLAHE. Defaults to True.\n",
    "        clahe_kernel_size_px (int, optional): Kernel size for CLAHE. Defaults to 25.\n",
    "        n_jobs (int, optional): Number of parallel jobs for processing. Defaults to -1.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, pd.DataFrame]: Images, body masks and the dataframe adjusted to the new crop region\n",
    "    \"\"\"\n",
    "\n",
    "    def rotate_crop_img(image: np.ndarray, rotation_deg: float) -> np.ndarray:\n",
    "        image = skimage.transform.rotate(image, rotation_deg)\n",
    "        image = image[image_crop_px:-image_crop_px, image_crop_px:-image_crop_px]\n",
    "        return image\n",
    "    \n",
    "\n",
    "    def rotate_pts_around_center(\n",
    "        pts: list[list[float]], \n",
    "        rot_center: Tuple[float, float], \n",
    "        degrees: float\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Rotate keypoints around a point (crop center)\n",
    "\n",
    "        Args:\n",
    "            pts (list[list[float]]): list of keypoints Nx2 like [[x1,y1], [x2,y2], ...]\n",
    "            rot_center (Tuple[float, float]): Point to rotate around\n",
    "            degrees (float): Amount to rotate in clockwise direction\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Rotated points in the same form as pts\n",
    "        \"\"\"\n",
    "\n",
    "        pts = np.asarray(pts, dtype=float)\n",
    "        cx, cy = rot_center\n",
    "        theta = np.deg2rad(-degrees)\n",
    "        c = np.array([cx, cy])\n",
    "        R = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                    [np.sin(theta),  np.cos(theta)]])\n",
    "        \n",
    "        # exclude inf values in marker data from rotation (because they can become nan)\n",
    "        mask = np.isfinite(pts).all(axis=1)\n",
    "        result = pts.copy()\n",
    "        finite_pts = pts[mask]\n",
    "        result[mask] = (R @ (finite_pts - c).T).T + c\n",
    "\n",
    "        return result\n",
    "\n",
    "    \n",
    "    def process_pose_data_and_extract_images_from_frame(\n",
    "        frame_detections: pd.DataFrame, \n",
    "        frame_path: str,\n",
    "        fetch_images: bool = True,\n",
    "        egocentric: bool = True\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, list[pd.Series]]:\n",
    "        images = []\n",
    "        body_masks = []\n",
    "        rows = []\n",
    "\n",
    "        assert frame_detections.frame_id.nunique() == 1\n",
    "\n",
    "        if fetch_images:\n",
    "            frame = imageio.v3.imread(frame_path, plugin=\"opencv\", colorspace=\"GRAY\")\n",
    "            if use_clahe:\n",
    "                frame = skimage.exposure.equalize_adapthist(frame, kernel_size=(clahe_kernel_size_px, clahe_kernel_size_px))\n",
    "\n",
    "        for _, row in frame_detections.iterrows():\n",
    "            body_center_adj_x = np.cos(row.orientation) * body_center_offset_px\n",
    "            body_center_adj_y = np.sin(row.orientation) * body_center_offset_px\n",
    "\n",
    "            if egocentric:\n",
    "                # so that bee is facing to the right (row.orientation + np.pi / 2 for facing upwards)\n",
    "                rotation_deg = (1 / (2 * np.pi)) * 360 * row.orientation\n",
    "            else:\n",
    "                rotation_deg = 0\n",
    "\n",
    "\n",
    "            # ---- transform marker locations to new cropped and rotated frame ----\n",
    "            center_of_crop = (image_size_px - 2 * image_crop_px) / 2\n",
    "\n",
    "            # calc. translated keypoints (adjust for body center offset)\n",
    "            la_x_trans = row.left_antenna_x - (row.x_pixels - center_of_crop) + body_center_adj_x\n",
    "            la_y_trans = row.left_antenna_y - (row.y_pixels - center_of_crop) + body_center_adj_y\n",
    "            ra_x_trans = row.right_antenna_x - (row.x_pixels - center_of_crop) + body_center_adj_x\n",
    "            ra_y_trans = row.right_antenna_y - (row.y_pixels - center_of_crop) + body_center_adj_y\n",
    "            prob_x_trans = row.proboscis_x - (row.x_pixels - center_of_crop) + body_center_adj_x\n",
    "            prob_y_trans = row.proboscis_y - (row.y_pixels - center_of_crop) + body_center_adj_y\n",
    "            head_x_trans = row.head_x - (row.x_pixels - center_of_crop) + body_center_adj_x\n",
    "            head_y_trans = row.head_y - (row.y_pixels - center_of_crop) + body_center_adj_y\n",
    "            thor_x_trans = row.thorax_x - (row.x_pixels - center_of_crop) + body_center_adj_x\n",
    "            thor_y_trans = row.thorax_y - (row.y_pixels - center_of_crop) + body_center_adj_y\n",
    "            abdo_x_trans = row.abdomen_tip_x - (row.x_pixels - center_of_crop) + body_center_adj_x\n",
    "            abdo_y_trans = row.abdomen_tip_y - (row.y_pixels - center_of_crop) + body_center_adj_y\n",
    "            \n",
    "            # rotate the points\n",
    "            rotated_pts = rotate_pts_around_center(pts=[\n",
    "                [la_x_trans, la_y_trans],\n",
    "                [ra_x_trans, ra_y_trans],\n",
    "                [prob_x_trans, prob_y_trans],\n",
    "                [head_x_trans, head_y_trans],\n",
    "                [thor_x_trans, thor_y_trans],\n",
    "                [abdo_x_trans, abdo_y_trans]\n",
    "            ], rot_center=(center_of_crop, center_of_crop), degrees=rotation_deg)\n",
    "\n",
    "            row.left_antenna_x = rotated_pts[0][0]\n",
    "            row.left_antenna_y = rotated_pts[0][1]\n",
    "            row.right_antenna_x = rotated_pts[1][0]\n",
    "            row.right_antenna_y = rotated_pts[1][1]\n",
    "            row.proboscis_x = rotated_pts[2][0]\n",
    "            row.proboscis_y = rotated_pts[2][1]\n",
    "            row.head_x = rotated_pts[3][0]\n",
    "            row.head_y = rotated_pts[3][1]\n",
    "            row.thorax_x = rotated_pts[4][0]\n",
    "            row.thorax_y = rotated_pts[4][1]\n",
    "            row.abdomen_tip_x = rotated_pts[5][0]\n",
    "            row.abdomen_tip_y = rotated_pts[5][1]\n",
    "\n",
    "            rows.append(row.values)\n",
    "                \n",
    "\n",
    "            if fetch_images:\n",
    "                center_x = row.x_pixels - body_center_adj_x\n",
    "                center_y = row.y_pixels - body_center_adj_y\n",
    "\n",
    "                # assert center point always within frame (even after trajectory extrapolation)\n",
    "                center_x = max(0, center_x)\n",
    "                center_x = min(frame.shape[1] - 1, center_x)\n",
    "                center_y = max(0, center_y)\n",
    "                center_y = min(frame.shape[0] - 1, center_y)\n",
    "\n",
    "                center = np.array((center_x, center_y))\n",
    "\n",
    "                image = bb_behavior.utils.images.get_crop_from_image(\n",
    "                    center, frame, width=image_size_px, clahe=False\n",
    "                )\n",
    "                image = (rotate_crop_img(image, rotation_deg) * 255).astype(np.uint8)\n",
    "\n",
    "                body_mask = np.zeros_like(frame)\n",
    "                body_coords = skimage.draw.ellipse(\n",
    "                    center[1],\n",
    "                    center[0],\n",
    "                    body_mask_length_px,\n",
    "                    body_mask_width_px,\n",
    "                    rotation=-(row.orientation - np.pi / 2),\n",
    "                    shape=frame.shape,\n",
    "                )\n",
    "                body_mask[body_coords] = 1\n",
    "                body_mask = (\n",
    "                    bb_behavior.utils.images.get_crop_from_image(\n",
    "                        center, body_mask, width=image_size_px, clahe=False\n",
    "                    )\n",
    "                    == 255\n",
    "                )\n",
    "                body_mask = rotate_crop_img(body_mask, rotation_deg) > 0.5\n",
    "\n",
    "                images.append(image)\n",
    "                body_masks.append(body_mask)\n",
    "        return images, body_masks, rows\n",
    "\n",
    "    if len(detections.index) == 0:\n",
    "        return\n",
    "\n",
    "    images = []\n",
    "    body_masks = []\n",
    "    rows = []\n",
    "\n",
    "    logger.debug(f'Detection count in video: {len(detections.index)}')\n",
    "    \n",
    "    detections_by_frame = detections.groupby(\"frame_id\")\n",
    "\n",
    "    # preload file paths because video_manager can't be used in parallel.\n",
    "    frame_paths = []\n",
    "    for _, frame_detections in detections_by_frame:\n",
    "        frame_paths.append(video_manager.get_frame_id_path(frame_detections.frame_id.iat[0]))\n",
    "    \n",
    "    logger.debug(f\"Processing {len(frame_paths)} cached images ...\")\n",
    "    parallel = joblib.Parallel(prefer=\"processes\", n_jobs=n_jobs)(\n",
    "        joblib.delayed(process_pose_data_and_extract_images_from_frame)(\n",
    "            frame_detections, \n",
    "            frame_path, \n",
    "            fetch_images=generate_videos, \n",
    "            egocentric=egocentric\n",
    "        )\n",
    "        for (_, frame_detections), frame_path in zip(detections_by_frame, frame_paths)\n",
    "    )\n",
    "\n",
    "    logger.debug(\"Processing of cached images complete.\")\n",
    "\n",
    "    for results in parallel:\n",
    "        images += results[0]\n",
    "        body_masks += results[1]\n",
    "        rows += results[2]\n",
    "\n",
    "    images = np.stack(images) if len(images) > 0 else np.array([])\n",
    "    body_masks = np.stack(body_masks) if len(body_masks) > 0 else np.array([])\n",
    "    detections = pd.DataFrame(np.stack(rows), columns=detections.columns)\n",
    "\n",
    "    return images, body_masks, detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af520b8b",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55bae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_short_inf_runs(s: pd.Series, max_gap: int = 10) -> pd.Series:\n",
    "    \"\"\"Interpolate missing data in regions, where the number of consecutive \n",
    "       missing points is <= max_gap\n",
    "\n",
    "    Args:\n",
    "        s (pd.Series): Input series\n",
    "        max_gap (int, optional): Maximum number of consecutive points, which get interpolated. \n",
    "            Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Interpolated series\n",
    "    \"\"\"\n",
    "    s = s.replace(np.inf, np.nan).copy()\n",
    "    isnan = s.isna()\n",
    "\n",
    "    # cumsum() increments at every number (at every non-NaN), so all consecutive NaNs get the same run id\n",
    "    run_ids = (~isnan).cumsum()\n",
    "\n",
    "    # dict{run_id: run_length}\n",
    "    run_length_dict = isnan.groupby(run_ids).sum().to_dict()\n",
    "\n",
    "    # map each element to its run length\n",
    "    run_lengths = run_ids.map(run_length_dict)\n",
    "\n",
    "    short_run_mask = isnan & (run_lengths <= max_gap)\n",
    "\n",
    "    interpolated = s.interpolate(method='linear')\n",
    "    interpolated[~short_run_mask & isnan] = np.nan\n",
    "    return interpolated\n",
    "\n",
    "\n",
    "def interpolate_missing_vals(df_video: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Interpolate missing data (some of it conditionally)\n",
    "\n",
    "    Args:\n",
    "        df_video (pd.DataFrame): Input dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Interpolated dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # interpolate inf values in orientation, coordinates and acceleration\n",
    "    cols_interpol = ['orientation', 'x_pixels', 'y_pixels', 'accel']\n",
    "    df_video[cols_interpol] = (\n",
    "        df_video\n",
    "        .groupby('bee_id', sort=False)[cols_interpol]\n",
    "        # use transform to use groupby and apply the methods inplace\n",
    "        .transform(lambda x: x.replace(np.inf, np.nan).interpolate(method='linear'))\n",
    "    )\n",
    "    # replace leading or trailing nans with 0\n",
    "    df_video[['accel']] = df_video[['accel']].fillna(0)\n",
    "\n",
    "    cols_cond_interpol = [\n",
    "        'left_antenna_x', 'left_antenna_y', \n",
    "        'right_antenna_x', 'right_antenna_y',\n",
    "        'proboscis_x', 'proboscis_y', \n",
    "        'head_x', 'head_y', \n",
    "        'thorax_x', 'thorax_y', \n",
    "        'abdomen_tip_x', 'abdomen_tip_y'\n",
    "    ]\n",
    "\n",
    "    for col in cols_cond_interpol:\n",
    "        df_video[col] = (\n",
    "            df_video\n",
    "            .groupby('bee_id', sort=False)[col]\n",
    "            # interpolate where run of 'inf'-values is 10 or shorter, otherwise inf becomes nan\n",
    "            .transform(lambda x: interpolate_short_inf_runs(x, max_gap=10))\n",
    "        )\n",
    "    \n",
    "    return df_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb0d844",
   "metadata": {},
   "source": [
    "## Cache frames, extract and process them and write to videos\n",
    "Main tasks:\n",
    "1. Cache all frames from the videos by iterating over each minute. \n",
    "2. From the cached frames extract all cropped and rotated frames showing the individual bees in the frames.\n",
    "3. Apply the mask and write the extracted frames to one-minute-long videos for each individual bee.\n",
    "4. Write the pose data adjusted to the new cropped and rotated frames to CSV-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c67440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vids_export_csv_one_minute(\n",
    "    video_name_short: str, \n",
    "    minute: int, \n",
    "    csv_writers: list, \n",
    "    images_masked: np.ndarray, \n",
    "    generate_videos: bool, \n",
    "    df_minute: pd.DataFrame\n",
    "):\n",
    "    \"\"\"For each bee writes one minute of original video (adjusted to the bee) to a video and\n",
    "       writes pose data for the bee to CSV-file\n",
    "\n",
    "    Args:\n",
    "        video_name_short (str): Short string from the original video (video-group + index)\n",
    "        minute (int): Minute of the original video\n",
    "        csv_writers (list): List of 4 CSV-writers, one for each bee\n",
    "        images_masked (np.ndarray): Extracted images multiplied with masks\n",
    "        generate_videos (bool): Whether to generate video clips\n",
    "        df_minute (pd.DataFrame): Dateframe for this minute\n",
    "    \"\"\"\n",
    "\n",
    "    # sort the df by bee_id and timestamp and apply the same sorting to the images\n",
    "    df_minute_sorted = df_minute.sort_values(['bee_id', 'time'])\n",
    "    sorting_indices = df_minute_sorted.index\n",
    "\n",
    "    if generate_videos:\n",
    "        images_sorted = [images_masked[i] for i in sorting_indices]\n",
    "\n",
    "    df_minute_grouped = df_minute_sorted.groupby('bee_id', sort=False)\n",
    "    # dict{bee_id -> indices}\n",
    "    df_minute_grouped_indices = df_minute_grouped.indices\n",
    "    df_minute_grouped_indices_iter = iter(df_minute_grouped_indices)\n",
    "    \n",
    "    for bee_id, df_bee_minute in df_minute_grouped:\n",
    "        if generate_videos:\n",
    "            indices_by_bee_id = df_minute_grouped_indices.get(next(df_minute_grouped_indices_iter))\n",
    "\n",
    "            start_time = df_bee_minute.time.iat[0]\n",
    "            end_time = df_bee_minute.time.iat[-1]\n",
    "            filename = \"_\".join((video_name_short, \"bee\" + str(bee_id), (str(math.floor(start_time)) + \"--\" + str(math.ceil(end_time))) + \".mp4\"))\n",
    "            images_bee = [images_sorted[i] for i in indices_by_bee_id]\n",
    "            video_manager.write_to_video(images=images_bee, filename=filename, frame_rate=FRAME_RATE)\n",
    "\n",
    "        # write to csv\n",
    "        coords_data = df_bee_minute[COLS_BODYPARTS_EXPORT].to_numpy()\n",
    "        data_rows = [[minute * FRAMES_PER_MINUTE + i, *row_arr] for i, row_arr in enumerate(coords_data)]\n",
    "        csv_writers[bee_id].writerows(data_rows)\n",
    "\n",
    "\n",
    "\n",
    "def process_minute(\n",
    "    video_file: str, \n",
    "    video_name_short: str, \n",
    "    df_video: pd.DataFrame, \n",
    "    rows_per_bee: int, \n",
    "    remainder_last_minute: int, \n",
    "    csv_writers: list, \n",
    "    minute: int, \n",
    "    generate_videos: bool,\n",
    "    total_minutes: int\n",
    "):\n",
    "    \"\"\"Process one minute of the original video\n",
    "\n",
    "    Args:\n",
    "        video_file (str): Original video file (including path)\n",
    "        video_name_short (str): Short string from the original video (video-group + index)\n",
    "        df_video (pd.DataFrame): Dateframe for original video\n",
    "        rows_per_bee (int): Total rows per bee in the dataframe for the original video (number of frames per bee)\n",
    "        remainder_last_minute (int): Remainder frames/rows in the last minute of the original video\n",
    "        csv_writers (list): List of 4 CSV-writers, one for each bee\n",
    "        minute (int): Minute of the original video (0-indexed)\n",
    "        generate_videos (bool): Whether to generate video clips\n",
    "        total_minutes (int): Number of total minutes rounded up in the original video to process \n",
    "            (excludes first five minutes, where bees are 'waking up')\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(f\"Processing minute {minute+1}\")\n",
    "    start_idx = minute * FRAMES_PER_MINUTE\n",
    "    end_idx = start_idx + 60 * FRAME_RATE\n",
    "    if minute == total_minutes - 1:\n",
    "        end_idx = start_idx + remainder_last_minute\n",
    "\n",
    "    df_minute_bee0 = df_video.iloc[start_idx:end_idx]\n",
    "    df_minute_bee1 = df_video.iloc[rows_per_bee + start_idx:rows_per_bee + end_idx]\n",
    "    df_minute_bee2 = df_video.iloc[2 * rows_per_bee + start_idx:2 * rows_per_bee + end_idx]\n",
    "    df_minute_bee3 = df_video.iloc[3 * rows_per_bee + start_idx:3 * rows_per_bee + end_idx]\n",
    "    df_minute = pd.concat([df_minute_bee0, df_minute_bee1, df_minute_bee2, df_minute_bee3])\n",
    "    \n",
    "    if generate_videos:\n",
    "        video_manager.cache_frames(\n",
    "            frame_ids=np.sort(df_minute['frame_id'].unique()), \n",
    "            video_name=video_file, \n",
    "            frame_indices=np.sort(df_minute['frame_index'].unique())\n",
    "        )\n",
    "\n",
    "    # get images and masks for all detections in one video\n",
    "    images, body_masks, df_minute_after = process_frames(\n",
    "        detections=df_minute, \n",
    "        video_manager=video_manager, \n",
    "        generate_videos=generate_videos, \n",
    "        n_jobs=N_JOBS\n",
    "    )\n",
    "\n",
    "    # apply all needed masks by multiplying them to the image\n",
    "    images_masked = images * body_masks if len(images) > 0 else np.array([])\n",
    "\n",
    "    generate_vids_export_csv_one_minute(\n",
    "        video_name_short, minute, \n",
    "        csv_writers, \n",
    "        images_masked, \n",
    "        generate_videos, \n",
    "        df_minute=df_minute_after\n",
    "    )\n",
    "\n",
    "    video_manager.clear_video_cache()\n",
    "\n",
    "\n",
    "\n",
    "def process_video(\n",
    "    video_filename: str, \n",
    "    df_video: pd.DataFrame, \n",
    "    generate_videos: bool\n",
    "):\n",
    "    \"\"\"Process one original video. Exports derived feature to CSV-file\n",
    "\n",
    "    Args:\n",
    "        video_filename (str): Original video file (including path)\n",
    "        df_video (pd.DataFrame): Dateframe for original video\n",
    "        generate_videos (bool): Whether to generate video clips\n",
    "    \"\"\"\n",
    "\n",
    "    video_name_short = (str(video_filename)).rsplit('/', 1)[1].split('.')[0]\n",
    "    logger.info(f\"Processing video {video_filename} ...\")\n",
    "\n",
    "    df_video = interpolate_missing_vals(df_video)\n",
    "    \n",
    "    df_video_grouped = df_video.groupby('bee_id', sort=False)\n",
    "    sizes = df_video_grouped.size()\n",
    "    # some video-datasets have a different number of rows for each bee, use last common frame-id\n",
    "    if sizes.nunique() != 1:\n",
    "        max_common_frame_index = df_video_grouped.frame_index.last().min()\n",
    "        df_video = df_video[df_video.frame_index <= max_common_frame_index].copy()\n",
    "        logger.warning(\n",
    "            f\"Different amounts of data for the bees detected! \\\n",
    "            Only extracting videos until frame index {max_common_frame_index} for each bee.\"\n",
    "        )\n",
    "        \n",
    "    n_rows = len(df_video)\n",
    "    logger.info(f\"Total rows for {video_name_short}: {len(df_video)}\")\n",
    "\n",
    "    rows_per_bee = int(n_rows / 4)\n",
    "    minutes = math.ceil(rows_per_bee / (60 * FRAME_RATE))\n",
    "    logger.info(f\"Minutes to process: {minutes}\")\n",
    "    logger.info(f\"Rows per bee (total framecount in exported videos): {rows_per_bee}\")\n",
    "    remainder_last_minute = rows_per_bee % FRAMES_PER_MINUTE\n",
    "    logger.debug(f\"Remainder frames per bee in the last minute: {remainder_last_minute}\")\n",
    "\n",
    "    seconds_start = MINUTES_CUTOFF_START * 60\n",
    "    seconds_end = math.ceil(seconds_start + (minutes - 1) * 60 + ((remainder_last_minute - 1) / FRAME_RATE))\n",
    "\n",
    "    with open(MARKER_DATA_OUTPUT_PATH + video_name_short + \"_bee0_\" + (str(seconds_start) + \"--\" + str(seconds_end)) +\n",
    "                \".csv\", 'w', newline='') as csvfile_0, \\\n",
    "        open(MARKER_DATA_OUTPUT_PATH + video_name_short + \"_bee1_\" + (str(seconds_start) + \"--\" + str(seconds_end)) + \n",
    "                \".csv\", 'w', newline='') as csvfile_1, \\\n",
    "        open(MARKER_DATA_OUTPUT_PATH + video_name_short + \"_bee2_\" + (str(seconds_start) + \"--\" + str(seconds_end)) + \n",
    "                \".csv\", 'w', newline='') as csvfile_2, \\\n",
    "        open(MARKER_DATA_OUTPUT_PATH + video_name_short + \"_bee3_\" + (str(seconds_start) + \"--\" + str(seconds_end)) + \n",
    "                \".csv\", 'w', newline='') as csvfile_3, \\\n",
    "        open(MARKER_DATA_OUTPUT_PATH + video_name_short + \"_deriv_features_\" + (str(seconds_start) + \"--\" + str(seconds_end)) + \n",
    "                \".csv\", 'w', newline='') as csvfile_deriv:\n",
    "        writer0 = csv.writer(csvfile_0, delimiter=',')\n",
    "        writer1 = csv.writer(csvfile_1, delimiter=',')\n",
    "        writer2 = csv.writer(csvfile_2, delimiter=',')\n",
    "        writer3 = csv.writer(csvfile_3, delimiter=',')\n",
    "        writer_deriv = csv.writer(csvfile_deriv, delimiter=',')\n",
    "        csv_writers = [writer0, writer1, writer2, writer3]\n",
    "        \n",
    "        writer0.writerows([['scorer'] + [''] * 15, BODYPARTS_HEADER, COORDS_HEADER])\n",
    "        writer1.writerows([['scorer'] + [''] * 15, BODYPARTS_HEADER, COORDS_HEADER])\n",
    "        writer2.writerows([['scorer'] + [''] * 15, BODYPARTS_HEADER, COORDS_HEADER])\n",
    "        writer3.writerows([['scorer'] + [''] * 15, BODYPARTS_HEADER, COORDS_HEADER])\n",
    "\n",
    "\n",
    "        writer_deriv.writerow(['frame', 'bee_id', 'accel'])\n",
    "        # is already sorted by bee and time\n",
    "        for bee_id, df_bee_video in df_video.groupby('bee_id', sort=False):\n",
    "            data = df_bee_video[['accel']].to_numpy()\n",
    "            data_rows = [[i, bee_id, *row_arr] for i, row_arr in enumerate(data)]\n",
    "            writer_deriv.writerows(data_rows)\n",
    "\n",
    "\n",
    "        for minute in range(minutes):\n",
    "            process_minute(\n",
    "                video_filename, \n",
    "                video_name_short, \n",
    "                df_video, \n",
    "                rows_per_bee, \n",
    "                remainder_last_minute, \n",
    "                csv_writers, \n",
    "                minute, \n",
    "                generate_videos,\n",
    "                total_minutes=minutes\n",
    "            )\n",
    "    \n",
    "df_grouped = df.groupby('video_filename', sort=False)\n",
    "for video_filename, df_video in df_grouped:\n",
    "    process_video(video_filename, df_video, GENERATE_VIDEOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6265262",
   "metadata": {},
   "source": [
    "# Merge videos\n",
    "Merge the minute-long videos of individuals into full videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94112c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_VIDEOS:\n",
    "    logger.info(\"Merging videos ...\")\n",
    "    files = sorted(glob.glob(VIDEO_OUTPUT_PATH + 'hex_*.mp4'))\n",
    "\n",
    "    video_part_map = {}\n",
    "    command = \"ffmpeg\"\n",
    "    path_to_command = \"/usr/local/bin/\"\n",
    "    command = path_to_command + command\n",
    "    input_videos_path = VIDEO_OUTPUT_PATH\n",
    "    merge_videos_path = \"/mnt/windows-ssd/trophallaxis_detection_code/data/\"\n",
    "    merge_txt_file = merge_videos_path + \"individual_videos_merged_konstanz.txt\"\n",
    "    merge_videos_output_path = merge_videos_path + \"individual_videos_merged_konstanz/\"\n",
    "\n",
    "    if not os.path.exists(merge_videos_output_path):\n",
    "        os.makedirs(merge_videos_output_path)\n",
    "\n",
    "    def create_merge_text_file(video_names):\n",
    "        logger.info(video_names)\n",
    "        with open(merge_txt_file, 'w') as f:\n",
    "            for video_name in video_names:\n",
    "                f.write(\"file \" + video_name + os.linesep)\n",
    "\n",
    "    for file in files:\n",
    "        file_parts = file.rsplit('_', 1)\n",
    "        start_frame = int((file_parts[1]).split('--')[0])\n",
    "        unique_file_part = file_parts[0]\n",
    "        video_part_map.setdefault(unique_file_part, SortedDict({})).update({start_frame: file})\n",
    "\n",
    "    for k, v in video_part_map.items():\n",
    "        create_merge_text_file(v.values())\n",
    "        with open(merge_txt_file, 'r+') as f:\n",
    "            lines = f.readlines()\n",
    "            first_line = str(lines[0]).rstrip()\n",
    "            last_line = str(lines[-1]).rstrip()\n",
    "            output_path = merge_videos_output_path\n",
    "            output_path += (first_line.split(input_videos_path)[1]).split(\"--\")[0]\n",
    "            output_path += \"--\" + (last_line.split(\"--\")[1])\n",
    "            if os.path.isfile(output_path):\n",
    "                os.remove(output_path)\n",
    "            call_args = [\"-f\", \"concat\", \"-safe\", \"0\", \"-i\", merge_txt_file,\n",
    "                \"-c\", \"copy\", output_path]\n",
    "            p = subprocess.Popen([command] + call_args, stderr=subprocess.PIPE)\n",
    "            stdout, stderr = p.communicate()\n",
    "            if p.returncode != 0:\n",
    "                # an error happened!\n",
    "                err_msg = \"%s. Code: %s\" % (stderr.strip(), p.returncode)\n",
    "                raise Exception(err_msg)\n",
    "            logger.info(\"Merging videos complete\")\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
